---
title: "CMM507 Coursework Part 2: <br> Evaluation and Comparison of Algorithm Effectiveness"
author: "Perkins Offi - 2114921"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_download: true
    number_sections: false
    toc: true
    toc_float:
      collapsed: false
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}
.scroll-100 {
  max-height: 300px;
  overflow-y: auto;
  background-color: inherit;
}
```



## <span style="color: blue;">Introduction.</span>


The use of machine learning algorithms in the world of business has evolved at lightning speed over the last few years. Algorithms have been designed to predict and execute all sorts of business aspects. Most times, several algorithms are proposed to solve the same problem and the best is usually chosen after appropriate evaluation of relative performances. In this project, a comparison of the performance/effectiveness of two such algorithms will be carried out.

The dataset (transactions.csv) contains synthetic data relating to a hypothetical research analysis on a set of online banking transactions. The dataset has 400 instances (rows) and 8 attributes (columns).

The purpose of the study for which the data has been gathered is to evaluate the effectiveness of the new algorithm, whose accuracies are given by variable model2, relative to the performance of the benchmark algorithm, whose accuracies are given by variable model1.

<br>

### Loading the dataset and necessary libraries.

The dataset which is in csv format was loaded using the read.csv function and saved in a variable called 'data'.

```{r}
#Set working directory
setwd("C:/Users/perki/Desktop/RGU/Data Science/Coursework/CMM507 Coursework 2")

#Load datasets
data = read.csv("transactions.csv", header = T, stringsAsFactors = T)
```

```{r message=FALSE}
library(ggplot2)
library(dplyr)
```
<br>

## <span style="color: blue;">Section 1: Visualisations and Summary Statistics.</span>


### 1.1 


#### Histogram plot showing the distribution of the values for model2.

```{r}
plot = ggplot(data = data, aes(x=model2))
plot = plot + geom_histogram(fill = 'orange', color = 'blue', binwidth = 1) + labs(title = "Histogram Showing The Distribution Of Values For Model2")
plot
```
<br><br>

#### Mean and median values for model2.
```{r class.output="bg-success"}
cat("Mean value for model2:", mean(data$model2), "\n")

cat("Median value for model2:", median(data$model2))

```
<br><br>

#### Commenting on whether model2 shows a normal distribution.
Confirming normality using the Shapiro-Wilk normality test.

```{r class.output="bg-success"}
shapiro.test(data$model2)
```
<br>

COMMENT: The histogram shows a normal distribution of model2 and this is confirmed by the Shapiro-Wilk normality test, with a p-value > 0.05 (0.07775) suggesting that the distribution of model2 is normal.

<br>

### 1.2 


#### Histogram plot showing the distribution of the values for value.

```{r}
plot3 = ggplot(data = data, aes(x=value))
plot3 = plot3 + geom_histogram(fill = 'orange', color = 'blue', binwidth = 20) + labs(title = "Histogram Showing The Distribution Of Value")
plot3
```
<br><br>

#### Mean and median values for value.
```{r class.output="bg-success"}
cat("Mean value for value:", mean(data$value), "\n")

cat("Median value for value:", median(data$value))

```
<br><br>

#### Commenting on whether value shows a normal distribution.
Confirming normality using the Shapiro-Wilk normality test.
```{r class.output="bg-success"}
shapiro.test(data$value)
```
<br>

COMMENT: The histogram and the Shapiro-Wilk test confirms that the distribution of value is NOT normal with a p-value < 0.05 (2.2e-16).

<br>

### 1.3 


#### Boxplot of the value variable split by the recipient category.
```{r}
bxplot = ggplot(data = data, aes(x=recipient, y=value, fill=recipient))
bxplot = bxplot + geom_boxplot() + labs(title = "Boxplot Of Value Split By Recipient Category")
bxplot
```
<br><br>

#### Mean and Standard Deviation of value for each type of recipient.
```{r class.output="bg-success"}
summarise(group_by(data, recipient), Means = mean(value), StDev = sd(value))
```
<br><br>

#### Comment critically on the dependence of value on the recipient type.
COMMENT: From the boxplot above, it is observed that apart from the purchase and transfer categories of recipient, all middle 50% of the values for each category are at different locations. The suggests that recipient type has an effect on value.

<br>

### 1.4


#### Scatterplot of time against value with the points colour coded according to the device.

```{r}
scplot = ggplot(data = data, aes(x=value, y=time, fill=device, color=device))
scplot = scplot + geom_point() + labs(title = "Scatterplot Of Time Against Value")
scplot
```
<br><br>

#### Correlation of value and time.
```{r class.output="bg-success"}
cor(data[c(5,6)])

cat("Correlation of value and time using spearman method = ", cor(x=data$value, y=data$time, method = "spearman"))

```
<br><br>

#### Comment critically on the dependence of time on value.
COMMENT: With a correlation of 0.1, both variables appear to have no (linear) relationship. Therefore, there is no dependence of time on value.
<br>

### 1.5


#### Stacked barplot of frequencies of device against status.
```{r}
sbplot = ggplot(data = data, aes(x=status, fill=device))
sbplot = sbplot + geom_bar(position="stack") + labs(title = "Stacked Barplot Of Frequencies Of Device Against Status")
sbplot
```
<br><br>

#### Stacked barplot of frequencies of status against device.
```{r}
sbplot2 = ggplot(data = data, aes(x=device, fill=status))
sbplot2 = sbplot2 + geom_bar(position="stack") + labs(title = "Stacked Barplot Of Frequencies Of Status Against Device")
sbplot2
```
<br><br>

#### Comment critically on the dependence of device and status.
COMMENT: The use of mobile and tablet devices appear to be higher for transactions executed by account holders to existing recipients than those executed to new recipients, while PC has the least number of transactions made to both new and existing recipients. Also, transactions by account holders to new recipients appear to be made more on mobile devices compared to PC and tablets.

<br>

## <span style="color: blue;">Section 2: Tables and Measures.</span>


### 2.1


#### A one-way table of frequencies (counts), relative proportion and cumulative frequencies for recipient.

```{r class.output="bg-success"}
t1 = table(data$recipient)
t1a = prop.table(t1)
t1b = cumsum(t1)

table1 = cbind(Frequencies = t1, Rel_proportion = round(t1a,2), Cummulative_Frequency = t1b)
table1
```
<br><br>

#### What are the most common, and what are the rarest recipient types?


The most common recipient type is 'Purchase'.
The rarest recipient type is 'Self'.

<br>

### 2.2


#### A two-way table of recipient (in rows) and status (in columns) normalised to show the fraction of status for each recipient type. 

```{r class.output="bg-success"}
t2 = xtabs(~recipient+status, data=data)
table2 = round(prop.table(t2),2)
table2
```
<br><br>

#### Comment critically on any interesting observations.
COMMENT: Transactions made to Existing recipients for purchases make up the highest proportion (0.30) while transactions made to a new recipient account that belongs to the account holder makes up the lowest proportion (0.01).  

<br>

### 2.3


#### A table showing the mean of model2 broken down by status.

```{r class.output="bg-success"}
summarise(group_by(data, status), means = mean(model2))
```
<br><br>

#### A table showing the mean of model2 broken down by device.

```{r class.output="bg-success"}
summarise(group_by(data, device), means = mean(model2))
```
<br><br>

#### Comment critically on any interesting observations.
COMMENT: Based on the means, Model2 has a higher performance for Existing recipients compared to New status. Also, Model2 performed better for transactions made on PC devices compared to mobile and tablet devices, performing least for tablet devices.

<br>

## <span style="color: blue;">Section 3: Significance Tests.</span>

### 3.1

#### Determining a 99% confidence interval for the mean value of model1.
```{r class.output="bg-success"}
tt = t.test(data$model1, alternative = "two.sided", conf.level = 0.99)
tt
```
The mean value of model1: 79.97367.

The 99% confidence interval for mean value of model1: 79.51758 - 80.42975.

<br><br>

#### Determining a 99% confidence interval for the mean value of model2.
```{r class.output="bg-success"}
tt2 = t.test(data$model2, alternative = "two.sided", conf.level = 0.99)
tt2
```
The mean value of model2: 82.07133.

The 99% confidence interval for mean value of model2: 81.5573 - 82.58537.

<br><br>

### 3.2

#### Paired two sample t-test to test for evidence of a difference in the performance of model2 compared to the performance of model1 across all the data, using a significance level of 0.05.

Defining the hypotheses for the paired t-test:<br>
H0 = The performances of model2 and model1 are the same.<br>
H1 = The performances of model2 and model1 are different.

```{r class.output="bg-success"}
ptt = t.test(x=data$model2, y=data$model1, alternative = "two.sided", paired = T, mu = 0, sig.level = 0.05)
ptt
```
<br>

The p-value (2.2e-16) is less than 0.05 so we reject the NULL hypothesis and accept the alternative hypothesis. There is a significant difference in the performances of model2 and model1.

At 95% confidence level the mean performance of model2 is between 1.73 and 2.46 higher than the mean performance of model1.

<br><br>

#### T-test to assess the hypothesis that model2 outperforms model1 by a difference of 2, using a significance level of 0.05. 

Defining the hypotheses for the paired t-test:<br>
H0 = Model2 outperforms model1 by a difference of 2.<br>
H1 = Model2 does not outperform model1 by a difference of 2.

```{r class.output="bg-success"}
ptt2 = t.test(x=data$model2, y=data$model1, alternative = "greater", paired = T, mu = 2, sig.level = 0.05)
ptt2
```

<br>

The p-value (0.2997) is greater than 0.05, so we cannot reject the NULL hypothesis. Model2 outperforms model1 by a difference of 2.

<br><br>

### 3.3

#### Non-parametric test to check for evidence of reduced performance of model2 on New recipients compared to Existing recipients, using a signifance level of 0.01.

Creating subsets of New and Existing recipients:
```{r class.output="bg-success"}
NewRecipient = data$model2[data$status == 'New']
ExistingRecipient = data$model2[data$status == 'Existing']
```

<br>

Defining the hypotheses for the Wilcoxon rank sum test:<br>
H0 = There is no evidence of reduced performance of Model2 on New recipients compared to Existing Recipients.<br>
H1 = There is evidence of reduced performance of Model2 on New recipients compared to Existing Recipients.
```{r class.output="bg-success"}
wt = wilcox.test(NewRecipient, ExistingRecipient, mu = 0, sig.level = 0.01, paired = F, exact = F, alternative = "less")
wt
```
<br>

Confirming with a Kruskal-wallis test
```{r class.output="bg-success"}
kruskal.test(model2 ~ status, data = data)
```

<br>

The p-value (2.2e-16) is less than 0.01, so we reject the Null hypothesis and accept the Alternative hypothesis. There is significant evidence of reduced performance of Model2 on New recipients compared to Existing Recipients.


<br><br>

####  Non-parametric test to check for a difference in performance of model2 for PC device compared to tablet device, using a signifance level of 0.01.

Creating subsets of PC and tablet devices:
```{r}
PC = data$model2[data$device == 'PC']
Tablet = data$model2[data$device == 'tablet']
```

<br>

Defining the hypotheses for the Wilcoxon rank sum test:<br>
H0 = The performance of Model2 for PC and Tablet Devices are the same.<br>
H1 = The performance of Model2 for PC and Tablet Devices are different.

```{r class.output="bg-success"}
wt2 = wilcox.test(PC, Tablet, mu = 0, sig.level = 0.01, paired = F, exact = F, alternative = "two.sided")
wt2
```
<br>

The p-value (0.1164) is greater than 0.01, so there is no significant evidence to reject the NULL hypothesis. There is no significant difference in the performance of Model2 for PC and Tablet Devices.

<br><br>

### 3.4

#### One-way analysis of variance (ANOVA) to compare the model2 performance for the different types of recipient, using a significance level of 0.05.

Defining the hypotheses for the ANOVA test:<br>
H0: Model2 Performance is the same for all types of recipient.<br>
H1: Model2 Performance is different for at least 2 types of recipient.

```{r class.output="bg-success"}
anova1 = aov(model2 ~ recipient, data = data)
summary(anova1)
```
<br>

The p-value is less than 0.05, so we have to reject the null hypothesis and accept the alternative hypothesis. Model2 Performance is different for at least 2 types of recipient.

<br><br>

#### Tukey’s multiple comparisons to compare the model2 performance for the different types of recipient, using a confidence level of 0.95.

```{r class.output="bg-success"}
tukey1 = TukeyHSD(anova1, conf.level = 0.95)
tukey1
plot(tukey1)
```

<br>

The Tukey's comparison shows that model2 performance of all four recipient categories are different.

<br><br>

#### Checking the assumptions required for ANOVA and comment in the validity of the test.

For an ANOVA test to be valid, the residuals must be normally distributed.<br>
Checking distribution of residuals to know the validity of the ANOVA test:

```{r}
#QQ plot of residuals
ResDf = data.frame(residuals = anova1$residuals)
ggplot(ResDf, aes(sample = residuals)) +
stat_qq() + stat_qq_line() + labs(title = "Q-Q Plot For ANOVA Residuals")
```

```{r class.output="bg-success"}
#Shapiro-wilk test for normality of residuals
shapiro.test(anova1$residuals)
```
<br>

COMMENT: From the point plot, it is observed that the residuals are normally distributed. The p-value from the Shapiro-wilk normality test further confirms the normality (p > 0.05).
Hence, the ANOVA test is VALID!

<br><br>

## <span style="color: blue;">Section 4: Experiment Design, Sample Sizes and Random Sampling.</span>

### 4.1

#### Calculating the standard deviation of model2
```{r class.output="bg-success"}
stdev = sd(data$model2)
cat("Standard deviation of model2 = ", stdev)
```

<br><br>

### 4.2

#### Calculating the minimum sample size required to perform a 2-sample t-test of statistical power 0.9 for establishing a difference of 2 in performance if a two-sided test is to be performed with significance level 0.05 and the estimated standard deviation assumed to be the value calculated in task 4.1 above.

```{r class.output="bg-success"}
pt1 = power.t.test(power = 0.9, delta = 2, sd = stdev, sig.level=0.05, type="two.sample", alternative = "two.sided")

pt1

cat("The recommended sample size = ", ceiling(pt1$n))
```

<br><br>

#### How large a sample would be needed to increase the power of the test to 0.99 with significance level 0.01?

```{r class.output="bg-success"}
pt2 = power.t.test(power = 0.99, delta = 2, sd = stdev, sig.level=0.01, type="two.sample", alternative = "two.sided")

pt2

cat("The recommended sample size = ", ceiling(pt2$n))
```

<br><br>

### 4.3

#### Let n be the first sample size calculated from 4.2 above. Create a data frame using a random sample of size n from transactions (with no duplicates).

```{r class.output="bg-success", class.output="scroll-100"}
set.seed(59)
num = 126
randomSelection = slice_sample(data, n = num, replace = F)
randomSelection
```

<br><br>

#### Comparing the distribution of the recipient values in the sample to the complete dataset.

```{r class.output="bg-success"}
table3 = rbind(Complete = prop.table(table(data$recipient)), 
               Random = prop.table(table(randomSelection$recipient)))
round(table3,2)
```

The distribution of the bill and transfer recipient types in the randomly generated dataset are different from the complete dataset, while the distribution of the purchase and self recipient types are the same as the complete dataset.

<br><br>

### 4.4

#### Suppose that you had intended to create a stratified random sample that had occurrences of recipient in the (approximately) same proportion as the transactions dataset. Create a dataframe (with no duplicates) of size n with these properties and ensure that the sample is reproducible.

```{r class.output="bg-success", class.output="scroll-100"}
set.seed(59)
GroupedDataset = group_by(data, recipient)
N = nrow(data)
StratifiedSelection = slice_sample(GroupedDataset, prop = num/N, replace = F)
print(StratifiedSelection, n = 126)
```
